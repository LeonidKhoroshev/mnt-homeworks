# Домашнее задание к занятию 13 «Введение в мониторинг» - Леонид Хорошев

## Обязательные задания

#### 1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчётов, которые сохраняются на диск. Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?

Минимальный набор метрик для данного проекта будет выглядеть следующим образом:
- CPU load average - среднее значение загрузки системы (значение в нормальном состоянии находится в диапазоне от 0 до 1, единица соответствует 100% загрузке одноядерной системы без перегруза). Данная метрика позволяет следить за нагрузкой на процессоры и не перегружать систему избыточными отчетами;
- FS - количество свободного места на диске, так как именно туда сохраняются текстовые отчеты, при переполнении дискового пространства данные высока вероятность потери информации из отчетов, которые не были сохранены на жесткий диск;
- IOPS - количество операций ввода/вывода (записи на диск), метрика позволяет отслеживать работоспособность оборудования (резкое повышение показателя IOPS может свидетельствовать о неисправности жестких дисков);
- количество http запросов (метрика может называться по-разному, например http_requests_total)  — метрика позволяет отслеживать величину нагрузки на нашу систему (резкий рост запросов может свидетельствовать о хакерских атаках, либо о других проблемах с доступом по http, в результате которых наша вычислительная платформа может быть неждоступна);
- уровень ошибок при http запросах (метрика может называться по-разному, например http_errors) — количество или частота неуспешно выполненных запросов, например, ответ 500 от HTTP-сервера (логика использования аналогична предыдущему пункту, большое количество ошибок при соединении свидетельствует о сетевых проблемах, а также о возможных сбоях в вычислительных системах).


#### 2. Менеджер продукта, посмотрев на ваши метрики, сказал, что ему непонятно, что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

2 из 3 приведенных выше показателей  (CPUla и RAM) показывают состояние нашей системы (нагрузку на оперативную память и процессор соответственно). С помощью них мы можем отслеживать нагрузку на нашу систему. На основе этих данных мы оперативно увеличиваем выделенные ресурсы при пиковых нагрузках или освобождаем их при её уменьшении, тем самым существенно экономим затраты (что особенно ценно при использование облаков и в целом при подходе "инфраструктура как сервис").

inodes (индексный дескриптор -  структура данных, в которой хранятся метаданные файла). Метрика показывает "здоровье" нашей файловой системы, так как нарушение структуры данных жестких дисков ведет к потере информации, в том числе критически важной.

Для менеджера данные показатели сами по себе могут ни о чем не говорить, но от них напрямую зависит качество обслуживания клиентов, поэтому на управленческом уровне целесообразно оперировать такими понятиями, как:
- SLI (service level indicator) - индикатор качества обслуживания. Конкретная величина предоставляемого обслуживания (например количество времени в год, когда наш сервис доступен, время отклика в секундах, процент успешных http запросов и т.д.). Чаще всего показатели представляются в процентном эквиваленте, где 100 % - отлично, а 0% - неприемлимо;
- SLO (service level objectives) — целевой уровень качества обслуживания (целевое значение наших SLI ).

На основании данных о целевых и реальных SLI менеджментом может быть принято решение о введении SLA (service level agreement) - соглашение об уровне обслуживания. Явный (штрафные санкции, зафиксированные юридически) или неявный (скидки, промокоды и т.д. в случае недовольства клиентов)контракт с внешними пользователями, включающий в себя последствия невыполнения SLO. 

#### 3. Вашей DevOps-команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики, в свою очередь, хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

Оптимальное решение - использование бесплатных систем сбора, мониторинга и анализа логов.

Самый популярный - стек ELK, состоящий из следующих программных продуктов:
- Elasticsearch - NoSQL база данных документов в формате JSON;
- Kibana - инструмент по визуализации данных (информацию с логов можно отслеживать в виде таблиц и диаграмм), для разработчиков может быть удобно разбивать данные по типам неисправностей и по сервисам, на которых они возникают;
- Logstash - конвейер обработки данных на стороне сервера, который получает данные из нескольких источников одновременно, парсит лог, а затем отправляет в базу данных Elasticsearch (позволяет обработать "сырые" данные для более удобного их восприятия, например убрать лишние символы, пробелы, структурировать данные и т.д.);
- Filebeat — доставщик лог-сообщений. Принцип его работы состоит в мониторинге и сборе лог-сообщений из лог-файлов и пересылке их в elasticsearch или logstash (один источник данных, в нашем случае сервис или приложение - один filebeat).

Данная технология широко применяется благодаря своей масштабируемости, отказоустойчивости и универсальности. Из явных минусов работы со стеком ELK можно отметить то, что системе требуется большое количество ресурсов CPU и RAM для работы, а также некоторые проблемы при начальной установке и настройке (проблемы cвязаны ограничением скачивания дистрибутивов из официальных репозиториев с российских ip-адресов, но легко решаемы с помошью зеркал, VPN и прокси).

В качестве альтернативного варианта можно также рассмотреть Clickhouse - СУБД с открытым исходным кодом колоночного типа, где данные хранятся и обрабатываются не по строкам, а по столбцам. Она стала широко применяемой благодаря быстрой обработке данных и масштабируемости. Если проводить аналогии со стеком ELK, то сам Clickhouse - это аналог Elasticsearch, Vector - собирает и обрабатывает логи (аналог Logstash и Filebeat в одном решении). Визуализацию нашего стека на базе Clickhouse можно настроить через Grafana. Clichouse также можно использовать совместно с [logstash](https://habr.com/ru/companies/crosstech/articles/546140/).

В заключении следует отметить, что недостатков в [Open source решениях по сбору логов](https://logit.io/blog/post/open-source-logging-tools/) нет, однако я бы остановил свой выбор на стеке ELK, как наиболее гибком, масштабируемом и популярном решении.



#### 4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA = 99% по http-кодам ответов. Этот параметр вычисляется по формуле: summ_2xx_requests/summ_all_requests. Он не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

Данная ситуация свидетельствует о налиции ответов 1xx (информационные ответы) и 3xx (перенаправления), они вполне могут считаться успешными. Следовательно для корректного рассчета SLA по данному показателю я бы использовал следующую формулу - SLA = 1-(summ_5xx_4хх_requests/summ_all_requests). То есть из общего количества запросов мы вычитаем долю неудачных.

#### 5. Опишите основные плюсы и минусы pull и push систем мониторинга.

Push-модель мониторинга подразумевает отправку данных с агентов в систему мониторинга, то есть такая система представляет собой базу данных, в которую стекается информация от агентов. Классический пример - рассмотренные ранее стеки ELK и Clickhouse. Преимуествами такой модели будут:
- простая репликация данных в разные системы мониторинга (к примеру logstash может направлять данные как в Elasticsearch так и в Clickhouse);
- более гибкая настройка отправки пакетов данных с метриками (данные можно фильтровать, перенастраивать вывод их на экран);
- высокая производительность, так как UDP протокол не слишком требовательный к качеству траффика.
  
Обычно push-модель используется для мониторинга больших систем, где количество устройств может быть слишком большим для ручного сбора данных (например логи).

Pull-модель - это когда сам сервер мониторинга ходит по пассивным экспортерам и забирает у них метрики. Главное преимущество подобной системы – единая точка конфигурирования, сам сервер, которому надо рассказать, что и откуда забирать, от сюда следует:
- легкость контролироля подлинности данных;
- возможность настройки единого proxy server до всех агентов с TLS;
- упрощённая отладка получения данных с агентов.
  
Но из такой конфигурации также вытекает и главный недостаток - при сетевых проблемах теряются все показатели за время простоя системы. 

#### 6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

Prometheus - pull-модель;
TICK - push-модель;
Zabbix -  гибридная модель;
VictoriaMetrics -  гибридная модель;
Nagios - push-модель.

#### 7. Склонируйте себе репозиторий и запустите TICK-стэк, используя технологии docker и docker-compose. В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (http://localhost:8888).

```
mkdir monitoring
cd monitoring
git init
git pull https://github.com/influxdata/sandbox
docker-compose up
```

![Alt_text](https://github.com/LeonidKhoroshev/mnt-homeworks/blob/MNT-video/10-monitoring-01-base/screenshots/mon1.png)


#### 8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer:
- Нажмите на кнопку Add a query
- Изучите вывод интерфейса и выберите БД telegraf.autogen
- В measurments выберите cpu->host->telegraf-getting-started, а в fields выберите usage_system. Внизу появится график утилизации cpu.
- Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.
